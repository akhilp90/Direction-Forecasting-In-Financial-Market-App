
import streamlit as st
import pandas as pd
import numpy as np
import pickle
import networkx as nx
import matplotlib.pyplot as plt
from statsmodels.tsa.stattools import grangercausalitytests
from datetime import datetime
import plotly.graph_objs as go

st.set_page_config(page_title="Stock Analysis App", layout="wide")

@st.cache_data
def load_data():
    return pd.read_csv("final_df.csv")

@st.cache_data
def prepare_graph(df):
    df['Date'] = pd.to_datetime(df['Date'])
    df = df.sort_values(['ticker', 'Date'])
    price_matrix = df.pivot(index='Date', columns='ticker', values='Close').dropna()
    returns = np.log(price_matrix / price_matrix.shift(1)).dropna()

    def granger_matrix(data, maxlag=5):
        stock_ids = data.columns
        result = pd.DataFrame(np.zeros((len(stock_ids), len(stock_ids))), columns=stock_ids, index=stock_ids)
        for y in stock_ids:
            for x in stock_ids:
                if x == y: continue
                try:
                    test_result = grangercausalitytests(data[[y, x]], maxlag=maxlag, verbose=False)
                    p_values = [test_result[i+1][0]['ssr_ftest'][1] for i in range(maxlag)]
                    result.loc[x, y] = min(p_values)
                except:
                    result.loc[x, y] = 1
        return result

    granger_pvals = granger_matrix(returns)
    threshold = 0.01
    G = nx.DiGraph()
    influence_data = []
    for from_node in granger_pvals.index:
        for to_node in granger_pvals.columns:
            p = granger_pvals.loc[from_node, to_node]
            if p < threshold:
                G.add_edge(from_node, to_node, weight=1 - p)
                influence_data.append({
                    "From": from_node,
                    "To": to_node,
                    "p-value": round(p, 6),
                    "Confidence": round((1 - p) * 100, 2)
                })
    influence_df = pd.DataFrame(influence_data).sort_values(by="Confidence", ascending=False)
    return G, influence_df

with open("AdaBoost_best_model.pkl", "rb") as f:
    model, scaler = pickle.load(f)

page = st.sidebar.radio("üìö Navigate", ["üìà Predict", "üï∏Ô∏è Influence Graph", "üìú History", "üß™ Backtest"])

if page == "üìà Predict":
    st.title("üìä Predict Tomorrow's Stock Direction")
    uploaded_file = st.file_uploader("üì§ Upload Feature CSV", type="csv")

    if uploaded_file:
        input_df = pd.read_csv(uploaded_file)
        st.write("üìã Uploaded Data:")
        st.dataframe(input_df)

        if st.button("üìà Predict"):
            try:
                input_scaled = scaler.transform(input_df)
                preds = model.predict(input_scaled)
                probas = model.predict_proba(input_scaled)

                results = input_df.copy()
                results['Prediction'] = ['üìà Up' if p == 1 else 'üìâ Down' for p in preds]
                results['Confidence'] = [f"{proba[p]*100:.2f}%" for p, proba in zip(preds, probas)]
                results['Timestamp'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

                st.success("‚úÖ Predictions Complete!")
                st.dataframe(results[['Prediction', 'Confidence', 'Timestamp']])
                st.download_button("üì• Download Predictions CSV", results.to_csv(index=False), "predictions.csv", "text/csv")

                try:
                    hist = pd.read_csv("prediction_history.csv")
                    pd.concat([hist, results]).to_csv("prediction_history.csv", index=False)
                except FileNotFoundError:
                    results.to_csv("prediction_history.csv", index=False)

                st.subheader("üß† Natural Language Insights")
                input_df_sample = input_df.iloc[:3]
                for i, row in input_df_sample.iterrows():
                    st.markdown(f"### Row {i+1} - Prediction: **{results['Prediction'][i]}** | Confidence: **{results['Confidence'][i]}**")
                    insights = []

                    if 'RSI_14' in row:
                        if row['RSI_14'] < 30:
                            insights.append("RSI is below 30 ‚Äî indicates oversold, possible reversal up.")
                        elif row['RSI_14'] > 70:
                            insights.append("RSI is above 70 ‚Äî suggests overbought, possible pullback.")
                        else:
                            insights.append("RSI is in neutral zone.")

                    if 'MACD' in row and 'MACD_signal' in row:
                        if row['MACD'] > row['MACD_signal']:
                            insights.append("MACD above signal line ‚Äî bullish signal.")
                        elif row['MACD'] < row['MACD_signal']:
                            insights.append("MACD below signal line ‚Äî bearish signal.")

                    if 'Volume' in input_df.columns:
                        avg_vol = input_df['Volume'].mean()
                        if row['Volume'] > 1.5 * avg_vol:
                            insights.append("High trading volume ‚Äî strong interest in the stock.")
                        elif row['Volume'] < 0.5 * avg_vol:
                            insights.append("Low trading volume ‚Äî weaker conviction or sideways trend.")
                        else:
                            insights.append("Volume is average ‚Äî no unusual activity.")

                    if 'Open' in row and 'Close' in row:
                        if row['Close'] > row['Open']:
                            insights.append("Bullish candlestick ‚Äî closing higher than opening.")
                        elif row['Close'] < row['Open']:
                            insights.append("Bearish candlestick ‚Äî closing lower than opening.")
                        else:
                            insights.append("Doji-like candle ‚Äî indecision in market.")

                    st.markdown("üìå " + "<br>üìå ".join(insights), unsafe_allow_html=True)

            except Exception as e:
                st.error(f"‚ùå Prediction failed: {e}")

elif page == "üï∏Ô∏è Influence Graph":
    st.title("üï∏Ô∏è Granger Causality Stock Influence Graph")
    st.markdown("Shows which stocks **influence** others based on Granger Causality (p < 0.01).")
    with st.spinner("üìä Generating graph..."):
        df = load_data()
        G, influence_df = prepare_graph(df)

        st.subheader("üîó Top Influencing Relationships")
        st.dataframe(influence_df.head(20), use_container_width=True)

        pos = nx.spring_layout(G, seed=42)
        node_x = []
        node_y = []
        node_text = []
        for node in G.nodes():
            x, y = pos[node]
            node_x.append(x)
            node_y.append(y)
            influences = len(list(G.successors(node)))
            followers = len(list(G.predecessors(node)))
            node_text.append(f"{node}<br>Influences: {influences}<br>Followers: {followers}")

        edge_x = []
        edge_y = []
        for edge in G.edges():
            x0, y0 = pos[edge[0]]
            x1, y1 = pos[edge[1]]
            edge_x.extend([x0, x1, None])
            edge_y.extend([y0, y1, None])

        edge_trace = go.Scatter(
            x=edge_x, y=edge_y,
            line=dict(width=1, color='#888'),
            hoverinfo='none',
            mode='lines')

        node_trace = go.Scatter(
            x=node_x, y=node_y,
            mode='markers+text',
            hoverinfo='text',
            textposition="bottom center",
            marker=dict(
                showscale=False,
                color='lightblue',
                size=15,
                line_width=2),
            text=list(G.nodes()),
            hovertext=node_text)

        fig = go.Figure(data=[edge_trace, node_trace],
                        layout=go.Layout(
                            title="üìå Stock Influence Network (p < 0.01)",
                            titlefont_size=16,
                            showlegend=False,
                            hovermode='closest',
                            margin=dict(b=20,l=5,r=5,t=40),
                            xaxis=dict(showgrid=False, zeroline=False),
                            yaxis=dict(showgrid=False, zeroline=False))
                       )
        st.plotly_chart(fig, use_container_width=True)

elif page == "üìú History":
    st.title("üìú Prediction History")
    try:
        hist_df = pd.read_csv("prediction_history.csv")
        st.dataframe(hist_df, use_container_width=True)
        st.download_button("üì• Download Full History", hist_df.to_csv(index=False), "prediction_history.csv")
    except FileNotFoundError:
        st.warning("No predictions made yet.")

elif page == "üß™ Backtest":
    st.title("üß™ Rule-Based Strategy Backtester")
    df = load_data()
    tickers = df['ticker'].unique()
    selected = st.selectbox("Choose Ticker", tickers)

    available_cols = df.columns.tolist()
    st.markdown(f"üìå Available Columns: `{', '.join(available_cols)}`")

    rule = st.text_input("Enter your rule (e.g. RSI_14 < 30 and MACD > 0)", "RSI_14 < 30 and MACD > 0")

    if st.button("Run Backtest"):
        try:
            sub = df[df['ticker'] == selected].copy()

            used_cols = [word for word in rule.replace(">", " ").replace("<", " ").replace("=", " ").split() if word in available_cols]
            undefined = [word for word in rule.replace(">", " ").replace("<", " ").replace("=", " ").split()
                         if word.isidentifier() and word not in available_cols and word not in ["and", "or", "not", "True", "False"]]

            if undefined:
                st.error(f"‚ùå These columns are not found in the data: {', '.join(undefined)}")
            else:
                sub['Signal'] = sub.eval(rule)
                sub['Return'] = sub['Close_next_day'] / sub['Close'] - 1
                sub['StrategyReturn'] = sub['Signal'] * sub['Return']

                st.metric("üìä Trades", int(sub['Signal'].sum()))
                st.metric("‚úÖ Win %", f"{(sub['StrategyReturn'] > 0).mean() * 100:.2f}%")
                st.metric("üìà Avg Return", f"{sub['StrategyReturn'].mean() * 100:.2f}%")

                st.line_chart(sub[['Return', 'StrategyReturn']].cumsum())

        except Exception as e:
            st.error(f"‚ùå Rule evaluation failed: {e}")
